{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf275154",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "# Term frequency, Inverse Document frequency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10c47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fca3d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go jurong point crazy Available bugis n great world la e buffet Cine got amore wat',\n",
       " 'Ok lar Joking wif u oni',\n",
       " 'Free entry wkly comp win FA Cup final tkts st May Text FA receive entry question std txt rate T C apply',\n",
       " 'U dun say early hor U c already say',\n",
       " 'Nah I think go usf life around though',\n",
       " 'FreeMsg Hey darling week word back I like fun still Tb ok XxX std chgs send rcv',\n",
       " 'Even brother like speak They treat like aid patent',\n",
       " 'As per request Melle Melle Oru Minnaminunginte Nurungu Vettam set callertune Callers Press copy friend Callertune',\n",
       " 'WINNER As valued network customer selected receivea prize reward To claim call Claim code KL Valid hour',\n",
       " 'Had mobile month U R entitled Update latest colour mobile camera Free Call The Mobile Update Co FREE',\n",
       " 'I gonna home soon want talk stuff anymore tonight k I cried enough today',\n",
       " 'SIX chance win CASH From pound txt CSH send Cost p day day TsandCs apply Reply HL info',\n",
       " 'URGENT You week FREE membership Prize Jackpot Txt word CLAIM No T C www dbuk net LCCLTD POBOX LDNW A RW',\n",
       " 'I searching right word thank breather I promise wont take help granted fulfil promise You wonderful blessing time',\n",
       " 'I HAVE A DATE ON SUNDAY WITH WILL']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('spam_cleaned_corpus_lemmatized.txt','r') as ptr:\n",
    "    corpus = ptr.read().split('\\n')\n",
    "    ptr.close()\n",
    "corpus[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c175556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tfidf.fit_transform(corpus).toarray()\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dae54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.43475724, 0.        , 0.        , 0.46143233,\n",
       "       0.54371108, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.54994964, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[0].shape)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fe1433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 21,\n",
       " 'great': 25,\n",
       " 'got': 24,\n",
       " 'wat': 88,\n",
       " 'ok': 58,\n",
       " 'free': 17,\n",
       " 'text': 76,\n",
       " 'txt': 85,\n",
       " 'say': 67,\n",
       " 'already': 0,\n",
       " 'think': 79,\n",
       " 'hey': 29,\n",
       " 'week': 91,\n",
       " 'back': 4,\n",
       " 'like': 40,\n",
       " 'still': 72,\n",
       " 'send': 69,\n",
       " 'friend': 18,\n",
       " 'prize': 63,\n",
       " 'to': 82,\n",
       " 'claim': 9,\n",
       " 'call': 6,\n",
       " 'mobile': 47,\n",
       " 'the': 77,\n",
       " 'co': 10,\n",
       " 'home': 31,\n",
       " 'want': 87,\n",
       " 'today': 83,\n",
       " 'cash': 8,\n",
       " 'day': 13,\n",
       " 'reply': 64,\n",
       " 'you': 98,\n",
       " 'no': 54,\n",
       " 'www': 95,\n",
       " 'right': 65,\n",
       " 'take': 74,\n",
       " 'time': 81,\n",
       " 'have': 28,\n",
       " 'message': 45,\n",
       " 'oh': 57,\n",
       " 'yes': 97,\n",
       " 'make': 44,\n",
       " 'way': 89,\n",
       " 'dont': 16,\n",
       " 'ur': 86,\n",
       " 'going': 22,\n",
       " 'so': 70,\n",
       " 'da': 12,\n",
       " 'lor': 41,\n",
       " 'just': 36,\n",
       " 'this': 80,\n",
       " 'know': 37,\n",
       " 'are': 2,\n",
       " 'do': 15,\n",
       " 'love': 42,\n",
       " 'let': 39,\n",
       " 'work': 94,\n",
       " 'what': 93,\n",
       " 'yeah': 96,\n",
       " 'but': 5,\n",
       " 'tell': 75,\n",
       " 'please': 61,\n",
       " 'if': 34,\n",
       " 'msg': 48,\n",
       " 'see': 68,\n",
       " 'how': 33,\n",
       " 'pls': 62,\n",
       " 'need': 51,\n",
       " 'we': 90,\n",
       " 'tomorrow': 84,\n",
       " 'hope': 32,\n",
       " 'well': 92,\n",
       " 'lt': 43,\n",
       " 'gt': 26,\n",
       " 'get': 19,\n",
       " 'ask': 3,\n",
       " 'happy': 27,\n",
       " 'sorry': 71,\n",
       " 'give': 20,\n",
       " 'new': 52,\n",
       " 'later': 38,\n",
       " 'your': 99,\n",
       " 'good': 23,\n",
       " 'come': 11,\n",
       " 'said': 66,\n",
       " 'it': 35,\n",
       " 'hi': 30,\n",
       " 'now': 55,\n",
       " 'much': 49,\n",
       " 'stop': 73,\n",
       " 'one': 59,\n",
       " 'night': 53,\n",
       " 'and': 1,\n",
       " 'dear': 14,\n",
       " 'my': 50,\n",
       " 'thing': 78,\n",
       " 'min': 46,\n",
       " 'number': 56,\n",
       " 'can': 7,\n",
       " 'phone': 60}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ea982",
   "metadata": {},
   "source": [
    "### we can also combine tfidf and n grams (n grams is a technique to increse vocabulary to cancle closeness of vectors when their document meaning is different but the words used in those documents are likely close/same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00be166",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2  = TfidfVectorizer(max_features=50,ngram_range=(2,3)) # I'm only taking bi and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "755a27a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5573, 50)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.] (50,)\n"
     ]
    }
   ],
   "source": [
    "x = tfidf2.fit_transform(corpus).toarray()\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x[5],x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b3f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to claim': 43,\n",
       " 'claim call': 7,\n",
       " 'free call': 13,\n",
       " 'chance win': 6,\n",
       " 'let know': 24,\n",
       " 'please call': 32,\n",
       " 'lt gt': 27,\n",
       " 'sorry call': 39,\n",
       " 'call later': 4,\n",
       " 'sorry call later': 40,\n",
       " 'hi hi': 21,\n",
       " 'customer service': 9,\n",
       " 'prize guaranteed': 35,\n",
       " 'guaranteed call': 18,\n",
       " 'valid hr': 46,\n",
       " 'prize guaranteed call': 36,\n",
       " 'selected receive': 37,\n",
       " 'your account': 48,\n",
       " 'urgent your': 44,\n",
       " 'your mobile': 49,\n",
       " 'call landline': 3,\n",
       " 'urgent your mobile': 45,\n",
       " 'wat time': 47,\n",
       " 'send stop': 38,\n",
       " 'co uk': 8,\n",
       " 'lt decimal': 25,\n",
       " 'decimal gt': 10,\n",
       " 'lt decimal gt': 26,\n",
       " 'good morning': 15,\n",
       " 'good night': 16,\n",
       " 'call now': 5,\n",
       " 'po box': 34,\n",
       " 'last night': 23,\n",
       " 'pls send': 33,\n",
       " 'new year': 30,\n",
       " 'take care': 41,\n",
       " 'gt min': 17,\n",
       " 'lt gt min': 28,\n",
       " 'call land': 1,\n",
       " 'land line': 22,\n",
       " 'call land line': 2,\n",
       " 'free text': 14,\n",
       " 'this nd': 42,\n",
       " 'do want': 11,\n",
       " 'ok lor': 31,\n",
       " 'every week': 12,\n",
       " 'happy new': 19,\n",
       " 'happy new year': 20,\n",
       " 'national rate': 29,\n",
       " 'await collection': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cea62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
